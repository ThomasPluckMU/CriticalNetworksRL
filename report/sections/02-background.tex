\subsection{Reinforcement Learning}

\subsection{Statistical Mechanics}

Criticality in statistical mechanics refers to phase transitions between states of matter. At criticality, systems exhibit "scale-free" correlations where microscopic and macroscopic scales become indistinguishable, manifesting as power-law distributions and long-range correlations that span all space and time scales of the system.

The Ising model is often used in studying criticality, where atoms in a lattice have spin states $s_i \in \{+1, -1\}$. Each atom $s_i$ couples to others with parameter $J_{ij}$ and experiences local bias from a field $h_i$. The energy of a configuration $\vec{s}$ is:
\begin{equation}E(\vec{s}) = \sum_{i\neq j} J_{ij} s_is_j + \sum_i h_is_i\end{equation}
This defines a Gibbs distribution over the states $\vec{s}$:
\begin{equation}\mathbb{P}(\vec{s})=\dfrac{1}{Z}\exp(-\beta E(\vec{s}))\end{equation}
with partition function $Z$ and inverse pseudotemperature $\beta$.

For neural systems, the mean-field approximation of highly connected Ising models is particularly relevant. In this approximation, the expected value of each spin is:
\begin{equation}
\langle s_i \rangle = \tanh(\beta(\sum_j J_{ij}\langle s_j \rangle + h_i))
\end{equation}
Which can be noted to bear a striking similarity to a hyperbolic tangent artificial neuron:
\begin{equation}
\sigma_i = \tanh(\sum_j w_{ij}x_j + b_i)
\end{equation}
Renormalization Group (RG) analysis allows us to understand scale-invariant behavior by coarse-graining (ie. averaging) the individual spins into blocks of size $b^d$ with block-spin variables given by:
\begin{equation}
S_I = \frac{1}{b^d}\sum_{i \in \text{block } I} s_i
\end{equation} When short-distance degrees of freedom are integrated out, we can derive an RG flow equation $dJ_{ij}/db$ and $dh_i/db$ for each parameter in our model. The system is at criticality when $dJ_{ij}/db=0$ and $dh_i/db=0$ therefore no change is exhibited with change of scale, in fact this constructs a critical manifold in parameter space.

\subsection{Criticality in Neural Systems}

The criticality hypothesis posits that biological neural systems self-organize to operate near critical points between ordered and chaotic dynamics \cite{Beggsetal2003, Beggsetal2012}. Empirical evidence includes observations of "neuronal avalanches" in cortical tissue with size distributions following power laws with exponents of approximately -3/2, matching predictions from critical branching processes \cite{Beggsetal2003}. 

Neural networks near criticality demonstrate optimal computational properties, including maximized dynamic range \cite{Kinouchietal2006, Shewetal2009}, information transmission \cite{Beggsetal2012}, and information storage capacity \cite{Bertschingeretal2004}. Conversely, deviations from criticality correlate with neural pathologies \cite{Meiseletal2011}, suggesting that maintaining criticality is essential for healthy brain function.

These findings motivate our approach: rather than training networks that may accidentally drift away from criticality, we leverage RG flow analysis to design networks that intrinsically maintain critical dynamics throughout operation.